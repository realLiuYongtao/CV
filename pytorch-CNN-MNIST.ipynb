{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"authorship_tag":"ABX9TyPTps3O6i0Lj5SAFdqr52Gj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# 查看显卡类型（是否成功安装）以及挂载谷歌云盘"],"metadata":{"id":"kKtXzEVbVHTu"}},{"cell_type":"code","source":["! nvidia-smi\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"25WrT5zLR3Dg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 引用模块"],"metadata":{"id":"f6l-w3iwVVSI"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import numpy as np\n","import cv2"],"metadata":{"id":"zHIYLwRkRR3I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 定义CNN的架构"],"metadata":{"id":"wl7avWMYVdHG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UiY9zmpDQL8G"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # 第一个卷积层，输入通道数为1，输出通道数为32，卷积核大小为3x3，padding大小为1\n","        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n","        # 第二个卷积层，输入通道数为32，输出通道数为64，卷积核大小为3x3，padding大小为1\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        # 第一个全连接层，输入大小为64*7*7，输出大小为128\n","        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n","        # 第二个全连接层，输入大小为128，输出大小为10\n","        self.fc2 = nn.Linear(128, 10)\n","    def forward(self, x):\n","        # 输入x的大小为[batch_size, 1, 28, 28]\n","        # 第一次卷积，使用ReLU作为激活函数\n","        x = nn.functional.relu(self.conv1(x)) # 输出大小为[batch_size, 32, 28, 28]\n","        # 第一次池化，使用2x2的最大池化操作\n","        x = nn.functional.max_pool2d(x, 2) # 输出大小为[batch_size, 32, 14, 14]\n","        # 第二次卷积，使用ReLU作为激活函数\n","        x = nn.functional.relu(self.conv2(x)) # 输出大小为[batch_size, 64, 14, 14]\n","        # 第二次池化，使用2x2的最大池化操作\n","        x = nn.functional.max_pool2d(x, 2) # 输出大小为[batch_size, 64, 7, 7]\n","        # 将特征张量展开成一维张量\n","        x = x.view(-1, 64 * 7 * 7) # 输出大小为[batch_size, 64*7*7]\n","        # 第一个全连接层，使用ReLU作为激活函数\n","        x = nn.functional.relu(self.fc1(x)) # 输出大小为[batch_size, 128]\n","        # 第二个全连接层，不使用激活函数\n","        x = self.fc2(x) # 输出大小为[batch_size, 10]\n","        return x\n"]},{"cell_type":"markdown","source":["# 定义超参数与数据加载器（从数据集中加载批量的图像）"],"metadata":{"id":"EtaLHNq8V__l"}},{"cell_type":"code","source":["# 定义超参数：\n","\n","# 每个批次的图像数量\n","batch_size = 64\n","# 学习率\n","learning_rate = 0.01\n","# 训练轮数\n","num_epochs = 10\n","\n","\n","# 定义数据加载器（从数据集中加载批量的图像）\n","\n","# 使用transforms.Compose定义了一个数据预处理管道，将图像转换为张量\n","# 对像素值进行归一化，将值从[0,1]范围缩放到[-1,1]范围。\n","transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5,), (0.5,))])\n","\n","\n","# 使用PyTorch中的datasets.MNIST加载MNIST数据集，并使用DataLoader将数据分成批次进行训练。\n","# 每个批次的图像数量为batch_size，shuffle=True表示每个批次都是随机的。\n","\n","# train_loader用于训练\n","train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# test_loader用于测试。\n","test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n","\n"],"metadata":{"id":"6CjCglImQ85W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 训练模型"],"metadata":{"id":"yqWfvcQ1WpQj"}},{"cell_type":"markdown","source":["使用nn.CrossEntropyLoss()损失函数。\n","使用optim.SGD优化器。\n","\n","接下来，使用for循环进行训练。外层循环迭代num_epochs次，内层循环迭代train_loader中的每个批次。在每个批次中，images和labels分别为图像张量和对应标签的张量。将images和labels转换为float和long数据类型，然后将优化器的梯度置零。使用网络模型net对图像进行预测，得到输出outputs。使用损失函数criterion计算预测输出outputs与真实标签labels之间的损失loss。调用loss.backward()方法自动计算梯度并反向传播，然后调用optimizer.step()方法更新网络参数。\n","\n","在训练过程中，每100个批次打印一次训练信息，包括当前轮数、训练轮数、当前批次、总批次数以及当前批次的损失值。"],"metadata":{"id":"XbP_BUSJaPib"}},{"cell_type":"code","source":["# 使用交叉熵损失函数和随机梯度下降优化器\n","net = Net()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n","\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.float()\n","        labels = labels.long()\n","\n","        optimizer.zero_grad()\n","        outputs = net(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if (i + 1) % 100 == 0:\n","            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","                  .format(epoch + 1, num_epochs, i + 1, len(train_loader), loss.item()))\n"],"metadata":{"id":"3uAWC0nsRKdx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 测试模型"],"metadata":{"id":"RaaRecMEWznZ"}},{"cell_type":"markdown","source":["这段代码的功能是评估训练好的神经网络在测试数据集上的准确率。\n","\n","初始化了两个变量 correct 和 total，用于记录测试集中正确预测的数量和测试集总共的图片数量。\n","\n","然后，我们使用 torch.no_grad() 上下文来关闭梯度计算，在评估过程中我们不需要计算梯度。\n","\n","在上下文中，迭代测试数据集，将每个批次的图像通过网络，并将预测的标签与真实标签进行比较，以计算正确预测的数量。\n","\n","最后，我们打印出网络在测试集上的准确率。"],"metadata":{"id":"fOJXyRNIavq4"}},{"cell_type":"code","source":["correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images = images.float()\n","        labels = labels.long()\n","\n","        outputs = net(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print('Accuracy of the network on the 10000 test images: {:.2f} %'.format(100 * correct / total))"],"metadata":{"id":"AzA7DRMLRC_z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"epNwJBoyRSQa"}}]}